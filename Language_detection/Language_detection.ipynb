{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cac4e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #Import to ML (scikit-learn), Data (Pandas) and Math (NumPy) Libraries\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "\n",
    "# #Data Loading from 'Kaggle'\n",
    "# df = pd.read_csv('language_detection.csv')\n",
    "\n",
    "# df.head(5)\n",
    "\n",
    "# \"\"\"### Value Counts of Language Label\"\"\"\n",
    "\n",
    "# df[\"language\"].value_counts()\n",
    "\n",
    "# \"\"\"### Value Counts of Text Feature\"\"\"\n",
    "\n",
    "# df[\"Text\"].value_counts()\n",
    "\n",
    "# \"\"\"> # *Process*\n",
    "# > * **Import to ML (scikit-learn) Libraries**\n",
    "# > * **Data Preprocessing**\n",
    "# > * **NLP system entegration to Data**\n",
    "# > * **Model Creating**\n",
    "# \"\"\"\n",
    "\n",
    "# #Import to ML (scikit-learn) Libraries\n",
    "# from sklearn.naive_bayes import MultinomialNB #RidgeClassifier\n",
    "\n",
    "# #Data Preprocessing\n",
    "# X_train, X_test, y_train, y_test = train_test_split(df.Text, \n",
    "#                                                     df.language,\n",
    "#                                                     test_size=0.325000000000000001,\n",
    "#                                                     random_state=2551,\n",
    "#                                                     shuffle=True)\n",
    "# #NLP system entegration to Data    \n",
    "# X_CountVectorizer = CountVectorizer(stop_words='english')\n",
    "\n",
    "# X_train_counts = X_CountVectorizer.fit_transform(X_train)\n",
    "\n",
    "# X_TfidfTransformer = TfidfTransformer()\n",
    "\n",
    "# X_train_tfidf = X_TfidfTransformer.fit_transform(X_train_counts)\n",
    "\n",
    "# #Model Creating\n",
    "# model = MultinomialNB()\n",
    "\n",
    "# model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# \"\"\"> # *Model Accuracy Score*\n",
    "# > * **model.score([Test_data])**\n",
    "# \"\"\"\n",
    "\n",
    "# model.score(X_CountVectorizer.transform(X_test),y_test)\n",
    "\n",
    "# \"\"\"> # *Prediction*\"\"\"\n",
    "\n",
    "# #Data of Prediction\n",
    "# text = \"\"\"I quite like him. \n",
    "# I'm so in love with him and my heart flutters when I see him.\"\"\"\n",
    "\n",
    "# text = [text]\n",
    "\n",
    "# text_counts = X_CountVectorizer.transform(text)\n",
    "\n",
    "# #Prediction Processing\n",
    "# prediction = model.predict(text_counts)\n",
    "\n",
    "# f\"Prediction is {prediction[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d24caa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c3a3362",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('language_detection.csv')\n",
    "train_data = dataset.iloc[:,:-1]\n",
    "y_train = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e858d918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Estonian      1000\n",
       "Swedish       1000\n",
       "English       1000\n",
       "Russian       1000\n",
       "Romanian      1000\n",
       "Persian       1000\n",
       "Pushto        1000\n",
       "Spanish       1000\n",
       "Hindi         1000\n",
       "Korean        1000\n",
       "Chinese       1000\n",
       "French        1000\n",
       "Portugese     1000\n",
       "Indonesian    1000\n",
       "Urdu          1000\n",
       "Latin         1000\n",
       "Turkish       1000\n",
       "Japanese      1000\n",
       "Dutch         1000\n",
       "Tamil         1000\n",
       "Thai          1000\n",
       "Arabic        1000\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"language\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff983ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kunal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0741d8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"qualsiasi persona che viene in negozio oggi ha diritto allo sconto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a17f884",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0, 22000):\n",
    "    review = dataset['Text'][i]\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "#     all_stopwords = stopwords.words('english')\n",
    "#     all_stopwords.remove('not')\n",
    "    review = [ps.stem(word) for word in review]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d48f0209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qualsiasi persona che viene in negozio oggi ha diritto allo sconto\n",
      "qualsiasi persona che viene in negozio oggi ha diritto allo sconto\n",
      "['qualsiasi', 'persona', 'che', 'vien', 'in', 'negozio', 'oggi', 'ha', 'diritto', 'allo', 'sconto']\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "text = text.lower()\n",
    "print(text)\n",
    "text = text.split(\" \")\n",
    "text = [ps.stem(word) for word in text]\n",
    "print(text)\n",
    "text = ' '.join(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af597f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [text]\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "X_test = cv.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a1c44b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = dataset.iloc[:,-1].values\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB()\n",
    "classifier.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f928643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3c07616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
    "\n",
    "# # Making the Confusion Matrix\n",
    "# from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "# print(cm)\n",
    "# accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa987604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['English']\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b150e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
