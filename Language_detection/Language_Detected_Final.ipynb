{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82612571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Imported basic Liberaries used for any algorithm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27fa6020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "dataset = pd.read_csv('language_detection.csv')\n",
    "train_data = dataset.iloc[:,:-1]\n",
    "y_train = dataset.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a5fb129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kunal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import re liberary for removing extra elements from the strings or to tokenize the string\n",
    "import re\n",
    "#  nitk liberary for Reduce words to their stems and to \n",
    "# remove some common words like the,in,is etc from the string which are of no use\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "# Stopword remove unnecessary words like the,is,not etc\n",
    "from nltk.corpus import stopwords\n",
    "# PorterStemmer reduces word to their stems\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7954e34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus is a list containing all filtered strings\n",
    "corpus = []\n",
    "for i in range(0, 22000):\n",
    "    review = dataset['Text'][i]\n",
    "    review = review.lower() # Convert uppercase letter in small case letters\n",
    "    review = review.split() # spilts each word and make array\n",
    "    ps = PorterStemmer() \n",
    "    review = [ps.stem(word) for word in review] # passes each word from ps.stem() to reduce words to there stems\n",
    "    review = ' '.join(review) # join words to recombine string\n",
    "    corpus.append(review) # append filtered string in corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98882f3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Import CountVectorizer from sklearn liberary used to convert strings into BOWs array\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 3000)\n",
    "X = cv.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecd49ad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4 17 19 ... 16  1 14]\n",
      "{4: 'Estonian', 17: 'Swedish', 19: 'Thai', 18: 'Tamil', 2: 'Dutch', 8: 'Japanese', 20: 'Turkish', 10: 'Latin', 21: 'Urdu', 7: 'Indonesian', 12: 'Portugese', 5: 'French', 1: 'Chinese', 9: 'Korean', 6: 'Hindi', 16: 'Spanish', 13: 'Pushto', 11: 'Persian', 14: 'Romanian', 15: 'Russian', 3: 'English', 0: 'Arabic'}\n"
     ]
    }
   ],
   "source": [
    "y_y = dataset.iloc[:,-1].values\n",
    "#  LabelEncoding used to convert column into vectors without increasing the number of column\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_y)\n",
    "print(y)\n",
    "\n",
    "#  dictionary to save each language where key value of languages is equal to there LabelEncoding vectored value\n",
    "dic_result = {}\n",
    "for i in range(len(y)):\n",
    "    dic_result[y[i]] = y_y[i]\n",
    "\n",
    "print(dic_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d57b431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203cd69e",
   "metadata": {},
   "source": [
    "# Uses Knn neighbourer algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4411fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# classifier = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "# classifier.fit(X_train, y_train)\n",
    "# 84 % accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c4defc",
   "metadata": {},
   "source": [
    "# Uses Logistic regression algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "911a40b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kunal\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# classifier = LogisticRegression(random_state = 0)\n",
    "# classifier.fit(X_train, y_train)\n",
    "# 93.33 % accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bf346b",
   "metadata": {},
   "source": [
    "# Uses SVM algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "78f0411f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.svm import SVC\n",
    "# classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "# classifier.fit(X_train, y_train)\n",
    "# 93.22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe03e4",
   "metadata": {},
   "source": [
    "# Uses decision tree algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f9165409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "# classifier.fit(X_train, y_train)\n",
    "# 91.05 %"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c53ee92",
   "metadata": {},
   "source": [
    "# Uses random forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ffd94f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "# classifier.fit(X_train, y_train)\n",
    "# 92.79"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4c3dd65",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "07e7a92c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9279545454545455"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac5655fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test string\n",
    "# text_ = \"В то время как центральное агентство Федеральной обороны США организовывает постоянные рейды, чтобы выследить его, Джек Стил Стил Джо Джек — андроид-охотник за головами, специализирующийся на огнестрельном оружии для гангстерских лимеров, чтобы вернуть своих товарищей Я нанял его, поэтому он, кажется, склонен наряжаться. Когда Железная Башня, а позже и люди генерала Марти присоединяются и пытаются помешать ей спасти союзника из Железной Башни, они разрушают ее с помощью Вайолет.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "229eb2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "В то время как центральное агентство Федеральной обороны США организовывает постоянные рейды, чтобы выследить его, Джек Стил Стил Джо Джек — андроид-охотник за головами, специализирующийся на огнестрельном оружии для гангстерских лимеров, чтобы вернуть своих товарищей Я нанял его, поэтому он, кажется, склонен наряжаться. Когда Железная Башня, а позже и люди генерала Марти присоединяются и пытаются помешать ей спасти союзника из Железной Башни, они разрушают ее с помощью Вайолет.\n",
      "в то время как центральное агентство федеральной обороны сша организовывает постоянные рейды чтобы выследить его джек стил стил джо джек — андроид-охотник за головами специализирующийся на огнестрельном оружии для гангстерских лимеров чтобы вернуть своих товарищей я нанял его поэтому он кажется склонен наряжаться. когда железная башня а позже и люди генерала марти присоединяются и пытаются помешать ей спасти союзника из железной башни они разрушают ее с помощью вайолет.\n"
     ]
    }
   ],
   "source": [
    "# print(text_)\n",
    "# text_ = re.sub(r'[!@#$(),\"%^*?:;~`0-9]', ' ', text_)\n",
    "# text_ = re.sub(r'[[]]', ' ', text_)\n",
    "# text_ = text_.lower()\n",
    "# text_ = text_.split()\n",
    "# text_ = [ps.stem(word) for word in text_]\n",
    "# text_ = ' '.join(text_)\n",
    "# print(text_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b8cd5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = [text_]\n",
    "# X_test = cv.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "823ad345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\n",
      "Russian\n"
     ]
    }
   ],
   "source": [
    "# y_pred = classifier.predict(X_test.toarray())\n",
    "# print(y_pred)\n",
    "# print(dic_result[y_pred[0]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
